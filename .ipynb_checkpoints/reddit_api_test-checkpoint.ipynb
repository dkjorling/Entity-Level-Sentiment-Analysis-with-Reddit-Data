{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6f1bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # require pandas 1.5.3 \n",
    "import numpy as np\n",
    "import decouple\n",
    "import requests\n",
    "import json\n",
    "import warnings\n",
    "import datetime as dt\n",
    "import os\n",
    "import re\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import reddit_requests as rr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fd7475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = decouple.AutoConfig(' ')\n",
    "key = config('APIKEY')\n",
    "pub = config('PUBLICKEY')\n",
    "user = config('USERNAME')\n",
    "pw = config('PW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7636f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 'kind' key t1_ = comment, t2=acct, t3=link, t4=message, t5=sub, t6=award\n",
    "auth = requests.auth.HTTPBasicAuth(pub, key)\n",
    "data = {\n",
    "    'grant_type': 'password',\n",
    "    'username': user,\n",
    "    'password': pw\n",
    "}\n",
    "\n",
    "headers = {'User-Agent': 'MYAPI/0.0.1'}\n",
    "res = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                    auth=auth, data=data, headers=headers)\n",
    "\n",
    "TOKEN = res.json()['access_token']\n",
    "headers = {**headers, **{'Authorization': f\"bearer {TOKEN}\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311820c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### scrape lakers stats ###\n",
    "# historical standings https://www.basketball-reference.com/friv/standings.fcgi?month=10&day=18&year=2022&lg_id=NBA\n",
    "# current roster https://www.basketball-reference.com/teams/LAL/2023.html#all_roster\n",
    "# win streak https://www.basketball-reference.com/teams/LAL/2023_games.html\n",
    "# would be pretty easy to manually do roster changes so not too worried ab that\n",
    "# otherwise just need game logs for each player and I can code up function to give stats up to that date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "01279eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use pushshift directly ###\n",
    "subreddit = 'lakers'\n",
    "start_date = dt.datetime(2022, 10, 15)\n",
    "end_date = dt.datetime(2022, 10, 19)\n",
    "start = int(start_date.timestamp())\n",
    "end = int(end_date.timestamp())\n",
    "\n",
    "api_query = 'https://api.pushshift.io/reddit/submission/search/' \\\n",
    "            + '?subreddit={}&limit=200&after={}&before={}'.format(subreddit, start, end)\n",
    "\n",
    "r = requests.get(api_query)\n",
    "json= r.json()\n",
    "df = pd.DataFrame(json['data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c46608b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 99)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "12bfeb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2022-10-19 06:50:14\n",
       "1      2022-10-19 06:40:13\n",
       "2      2022-10-19 06:27:07\n",
       "3      2022-10-19 06:25:07\n",
       "4      2022-10-19 06:22:24\n",
       "              ...         \n",
       "123    2022-10-15 13:49:40\n",
       "124    2022-10-15 13:08:29\n",
       "125    2022-10-15 10:50:36\n",
       "126    2022-10-15 10:44:58\n",
       "127    2022-10-15 10:42:55\n",
       "Name: utc_datetime_str, Length: 128, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.utc_datetime_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3caa690a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1665990000 1666076400\n"
     ]
    }
   ],
   "source": [
    "start_date = dt.datetime(2022, 10, 15)\n",
    "end_date = dt.datetime(2022, 10, 18)\n",
    "start = int(start_date.timestamp())\n",
    "end = int(end_date.timestamp())\n",
    "\n",
    "print(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1afc47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_more_posts(start, end, subreddit='lakers', limit=50):\n",
    "    \"\"\" Get reddit posts back to the passed start_date.  \n",
    "        \n",
    "        Parameters\n",
    "        \n",
    "        -start_date must be in YYYY-MM-DD string format\n",
    "    \n",
    "    \"\"\"\n",
    "    start = int(start.timestamp())\n",
    "    end = int(end.timestamp())\n",
    "    \n",
    "    api_query = 'https://api.pushshift.io/reddit/submission/search/' \\\n",
    "                + '?subreddit={}&limit={}&after={}&before={}'.format(subreddit, limit, start, end)\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(api_query)\n",
    "        json= r.json()\n",
    "        df = pd.DataFrame(json['data'])\n",
    "    \n",
    "        df = df[['utc_datetime_str', 'id', 'title', 'author', 'selftext', 'upvote_ratio']]\n",
    "        print(\"Successfully pulled data\")\n",
    "        return df\n",
    "    except:\n",
    "        print(\"Upload failed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8db651f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_10_19\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_10_22\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_10_23\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_10_27\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_10_28\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_10_30\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_01\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_04\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_05\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_06\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_08\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_09\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_10\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_11\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_15\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_16\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_17\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_18\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_20\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_21\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_23\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_25\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_26\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_27\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_28\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_29\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_11_30\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_02\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_03\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_04\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_05\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_08\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_09\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_10\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_11\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_12\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_13\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_14\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_15\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_16\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_17\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_18\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_19\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_20\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_21\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_22\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_24\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_26\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_28\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_30\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2022_12_31\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_01_01\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_01_07\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_01_10\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_01_11\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_01_15\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_01_16\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_01_17\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_01_18\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_01_19\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_01_20\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_01_21\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_01_23\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_01_24\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_01_26\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_01_29\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_02_01\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_02_03\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_02_06\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_02_09\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_02_12\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_02_15\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_02_16\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_02_17\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_02_18\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_02_19\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_02_20\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_02_23\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_02_25\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_02_26\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_01\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_02\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_05\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_08\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_10\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_11\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_12\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_13\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_14\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_17\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_22\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_23\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_25\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_26\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_27\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_28\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_31\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_04_04\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_04_06\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_04_07\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_04_08\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_04_09\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_04_11\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_04_14\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_04_17\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_04_18\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_04_19\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n",
      "Upload failed\n",
      "Failed to Upload Data\n"
     ]
    }
   ],
   "source": [
    "# run through a hacky for loop\n",
    "base = dt.datetime(2023, 4, 12)\n",
    "date_list = [base - dt.timedelta(days=x) for x in range(186)]\n",
    "\n",
    "bad_dates = []\n",
    "for date in date_list:\n",
    "    start = date\n",
    "    end = start + dt.timedelta(days=1)\n",
    "    df = get_more_posts(start, end)\n",
    "    try:\n",
    "        start_string = start.strftime('%Y_%m_%d')\n",
    "        df.to_csv('data/r_lakers_{}'.format(start_string))\n",
    "        print(\"Successfully uploaded data for {}\".format(start_string))\n",
    "    except:\n",
    "        print(\"Failed to Upload Data for {}\".format(start_string))\n",
    "        bad_dates.append(start_string.replace('_', '-'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "964256a9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023-02-26',\n",
       " '2023-02-16',\n",
       " '2022-10-23',\n",
       " '2023-04-06',\n",
       " '2023-03-11',\n",
       " '2022-11-15',\n",
       " '2023-03-18',\n",
       " '2022-12-04',\n",
       " '2022-11-23',\n",
       " '2023-04-09',\n",
       " '2022-12-02',\n",
       " '2023-03-26',\n",
       " '2023-03-10',\n",
       " '2023-04-07',\n",
       " '2023-03-17',\n",
       " '2022-12-11',\n",
       " '2022-11-09',\n",
       " '2022-12-18',\n",
       " '2022-11-06',\n",
       " '2022-12-21',\n",
       " '2023-03-02',\n",
       " '2023-03-05',\n",
       " '2022-11-30',\n",
       " '2022-12-28',\n",
       " '2022-10-30',\n",
       " '2023-01-15',\n",
       " '2023-01-23',\n",
       " '2023-02-03',\n",
       " '2022-10-19',\n",
       " '2022-10-28',\n",
       " '2023-02-15',\n",
       " '2022-10-27',\n",
       " '2023-02-23',\n",
       " '2022-11-29',\n",
       " '2023-03-12',\n",
       " '2022-11-11',\n",
       " '2022-11-18',\n",
       " '2022-11-27',\n",
       " '2023-03-23',\n",
       " '2022-11-20',\n",
       " '2023-03-22',\n",
       " '2022-11-26',\n",
       " '2023-03-14',\n",
       " '2022-11-10',\n",
       " '2022-11-28',\n",
       " '2023-04-04',\n",
       " '2023-03-31',\n",
       " '2023-04-19',\n",
       " '2023-04-17',\n",
       " '2022-11-04',\n",
       " '2023-04-11',\n",
       " '2023-03-01',\n",
       " '2022-12-13',\n",
       " '2023-02-01',\n",
       " '2023-01-29',\n",
       " '2023-02-09',\n",
       " '2023-01-20']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for min files that need to be re-uploaded\n",
    "def check_for_max_posts(limit = 50)\n",
    "    directory = '/Users/dylanjorling/NBASA_reddit/data'\n",
    "    files = os.listdir(directory)\n",
    "    files = [x for x in files if len(re.findall(r\"r_lakers\", x)) == 1]\n",
    "    min_files = []\n",
    "    for file in files:\n",
    "        try:\n",
    "            x = pd.read_csv('data/' + file)\n",
    "            if x.shape[0] == limit:\n",
    "                min_files.append(file)\n",
    "        except:\n",
    "            continue\n",
    "    min_files_date = [file[9:] for file in min_files]\n",
    "    min_files_date = [file.replace('_', '-') for file in min_files_date]\n",
    "    return min_files_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d373df86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "base = dt.datetime(2023, 4, 12)\n",
    "date_list = [base - dt.timedelta(days=x) for x in range(186)]\n",
    "date_list = [x.strftime('%Y-%m-%d') for x in date_list]\n",
    "file_list = [file.replace('_', '-')[9:] for file in files]\n",
    "file_list.remove('')\n",
    "\n",
    "new_date_list = [x for x in date_list if x not in file_list]\n",
    "print(len(new_date_list))\n",
    "new_date_list.append(min_files_date)\n",
    "print(len(new_date_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6647b908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n"
     ]
    }
   ],
   "source": [
    "new_date_list = new_date_list[:78] \n",
    "for x in min_files_date:\n",
    "    new_date_list.append(x)\n",
    "print(len(new_date_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c1dfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload failed\n",
      "Failed to Upload Data for 2023-04-12\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_04_10\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_04_05\n",
      "Upload failed\n",
      "Failed to Upload Data for 2023-04-03\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_04_02\n",
      "Upload failed\n",
      "Failed to Upload Data for 2023-04-01\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_30\n",
      "Upload failed\n",
      "Failed to Upload Data for 2023-03-29\n",
      "Upload failed\n",
      "Failed to Upload Data for 2023-03-24\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_21\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_20\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_19\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_16\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_15\n",
      "Upload failed\n",
      "Failed to Upload Data for 2023-03-09\n",
      "Upload failed\n",
      "Failed to Upload Data for 2023-03-07\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_06\n",
      "Upload failed\n",
      "Failed to Upload Data for 2023-03-04\n",
      "Successfully pulled data\n",
      "Successfully uploaded data for 2023_03_03\n",
      "Upload failed\n",
      "Failed to Upload Data for 2023-02-28\n"
     ]
    }
   ],
   "source": [
    "# run through a hacky for loop\n",
    "\n",
    "bad_dates = []\n",
    "for date in new_date_list:\n",
    "    start = dt.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    end = start + dt.timedelta(days=1)\n",
    "    df = get_more_posts(start, end, limit=200)\n",
    "    try:\n",
    "        start_string = start.strftime('%Y_%m_%d')\n",
    "        df.to_csv('data/r_lakers_{}'.format(start_string))\n",
    "        print(\"Successfully uploaded data for {}\".format(start_string))\n",
    "    except:\n",
    "        start_string2 = start.strftime('%Y-%m-%d')\n",
    "        print(\"Failed to Upload Data for {}\".format(start_string2))\n",
    "        bad_dates.append(start_string2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a0beced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 1, 1, 0, 0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime.strptime('2022-01-01', '%Y-%m-%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
